{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "0d12d05ab1afc7278cbb1fa09e775842eb34e7aa5a193c340acf9f8f1f5bb7ed"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "(유형1) 정규화"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<built-in method sum of numpy.ndarray object at 0x000001E7CA526B70>\n[0.58809524]\n[0.68095238]\n[0.6547619]\n[1.]\n[0.52380952]\n[0.59166667]\n[0.64285714]\n[0.65595238]\n[0.52380952]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = 'C:/Users/KKK/Desktop/[Dataset] 작업형 제1유형/mtcars.csv'\n",
    "\n",
    "# Get Dataframe\n",
    "df = pd.read_csv(path, encoding='cp949')\n",
    "subdf = df['qsec']\n",
    "x = subdf.values.reshape(-1,1)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "y=scaler.fit_transform(x)\n",
    "\n",
    "print((y>0.5).sum)\n",
    "for i in y:\n",
    "    if i >0.5:\n",
    "        print(i)"
   ]
  },
  {
   "source": [
    "(유형 1) 가설 검정 t-test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ttest_indResult(statistic=-3.942497394147243, pvalue=0.00044711126996750043)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "fast = df[df['qsec']<=20]\n",
    "slow = df[df['qsec']>20]\n",
    "t_test = stats.ttest_ind(fast['qsec'], slow['qsec'])\n",
    "\n",
    "print(t_test)\n"
   ]
  },
  {
   "source": [
    "(유형 2) 풀이 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Power_divergenceResult(statistic=46.018193092876174, pvalue=0.040349220148313714)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "result = chisquare(df['qsec'], f_exp=df['mpg'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer # 왜 썻을까?\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "path = 'C:/Users/KKK/Desktop/[Dataset] 작업형 제2유형/'\n",
    "X_train_path = path +'X_train.csv'\n",
    "X_test_path = path + 'X_test.csv'\n",
    "y_train_path = path + 'y_train.csv'\n",
    "y_test_path = path + '1234.csv'\n",
    "\n",
    "# Get Dataframe\n",
    "X_train = pd.read_csv(X_train_path, encoding='cp949')\n",
    "X_train = X_train.iloc[:, 1:]\n",
    "\n",
    "X_test = pd.read_csv(X_test_path , encoding='cp949')\n",
    "#cust id 먼저\n",
    "X_test_id = X_test.iloc[:,0]\n",
    "X_test = X_test.iloc[:, 1:]\n",
    "\n",
    "y_train = pd.read_csv(y_train_path)\n",
    "y_train = y_train.iloc[:,-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelEncoder\n",
    "X_train.loc[:, ['주구매상품','주구매지점']] = \\\n",
    "    X_train.loc[:, ['주구매상품','주구매지점']].apply(LabelEncoder().fit_transform)\n",
    "X_train.loc[:, ['환불금액']] = \\\n",
    "    X_train.loc[:, ['환불금액']].fillna(0)\n",
    "\n",
    "X_test.loc[:, ['주구매상품','주구매지점']] = \\\n",
    "    X_test.loc[:, ['주구매상품','주구매지점']].apply(LabelEncoder().fit_transform)\n",
    "X_test.loc[:, ['환불금액']] = \\\n",
    "    X_test.loc[:, ['환불금액']].fillna(0)\n",
    "\n",
    "# OneHotEncoder\n",
    "\n",
    "# X_train = pd.get_dummies( X_train.loc[:, ['주구매상품']])\n"
   ]
  },
  {
   "source": [
    "IQR 이상치 제거"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          총구매액     최대구매액       환불금액  주구매상품  ...  내점일수   내점당구매건수    주말방문비율  구매주기\n0     68282840  11264000  6860000.0      5  ...    19  3.894737  0.527027    17\n1      2136000   2136000   300000.0     21  ...     2  1.500000  0.000000     1\n2      3197000   1639000        0.0      6  ...     2  2.000000  0.000000     1\n3     16077620   4935000        0.0      5  ...    18  2.444444  0.318182    16\n4     29050000  24000000        0.0     15  ...     2  1.500000  0.000000    85\n...        ...       ...        ...    ...  ...   ...       ...       ...   ...\n3494  95835000  81650000        0.0     17  ...     7  1.285714  0.111111    34\n3495   3175200   3042900        0.0      3  ...     1  2.000000  1.000000     0\n3496  29628600   7200000  6049600.0     22  ...     8  1.625000  0.461538    40\n3497     75000     75000        0.0     32  ...     1  1.000000  0.000000     0\n3498   1875000   1000000        0.0     41  ...     2  1.000000  0.000000    39\n\n[3144 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# def get_outlier(df=None, column=None, weight=1.5):\n",
    "#   # target 값과 상관관계가 높은 열을 우선적으로 진행\n",
    "#   quantile_25 = np.percentile(df[column].values, 25)\n",
    "#   quantile_75 = np.percentile(df[column].values, 75)\n",
    "\n",
    "#   IQR = quantile_75 - quantile_25\n",
    "#   IQR_weight = IQR*weight\n",
    "  \n",
    "#   lowest = quantile_25 - IQR_weight\n",
    "#   highest = quantile_75 + IQR_weight\n",
    "  \n",
    "#   outlier_idx = df[column][ (df[column] < lowest) | (df[column] > highest) ].index\n",
    "#   return outlier_idx\n",
    "\n",
    "# outlier_idx = get_outlier(df=X_train, column='총구매액', weight=1.5)\n",
    "# X_train.drop(outlier_idx, axis=0, inplace=True)\n",
    "# print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LR ROCAUC Score:  0.6352677527639534\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print('LR ROCAUC Score: ', roc_auc_score(y_train, pd.DataFrame(model.predict_proba(X_train)).iloc[:,1]))\n",
    "\n",
    "predict = model.predict_proba(X_test)\n",
    "predict = pd.DataFrame(predict)\n",
    "predict =predict.iloc[:, 1]\n",
    "\n",
    "# LR Model Predict\n",
    "answer = pd.concat([X_test_id, predict], axis = 1)\n",
    "answer.to_csv(y_test_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NN ROCAUC Score 0.576493731698899\n"
     ]
    }
   ],
   "source": [
    "# MLP\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (10, ), solver = 'adam', activation = 'relu', learning_rate_init = 0.001, max_iter = 500)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "print('MLP ROCAUC Score', roc_auc_score(y_train, pd.DataFrame(mlp.predict_proba(X_train)).iloc[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NN ROCAUC Score 0.7386293101528664\n"
     ]
    }
   ],
   "source": [
    "#RF\n",
    "rf = RandomForestClassifier(n_estimators = 100, max_depth = 5, random_state = 999)\n",
    "rf.fit(X_train, y_train)\n",
    "print('RF ROCAUC Score', roc_auc_score(y_train, pd.DataFrame(rf.predict_proba(X_train)).iloc[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNN ROCAUC SCORE 0.78464579366935\n0       0.0\n1       0.2\n2       0.2\n3       0.4\n4       0.0\n       ... \n2477    0.8\n2478    0.4\n2479    0.4\n2480    0.2\n2481    1.0\nName: 1, Length: 2482, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# kNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "print('KNN ROCAUC SCORE', roc_auc_score(y_train, pd.DataFrame(knn.predict_proba(X_train)).iloc[:,1]))\n",
    "\n",
    "predict = pd.DataFrame(knn.predict_proba(X_test)).iloc[:,1]\n",
    "print(predict)\n",
    "\n",
    "answer = pd.concat([X_test_id, predict], axis = 1)\n",
    "answer.to_csv(y_test_path, index = False)\n"
   ]
  }
 ]
}